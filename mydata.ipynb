{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Questions:\n",
    "#   What is priority and how is it calculated?\n",
    "#   Can we assume that measure B will always be subtracted from measure A when it appears?\n",
    "\n",
    "# TODO Implement:\n",
    "# Apply tests to each vessel\n",
    "# Return results in given format\n",
    "\n",
    "# List of each check per file. Return FACILITY_CODE, VESSEL_CODE, CYCLE_CODE, CYCLE_STATUS_CODE, EXPOSURE_STATUS_CODE,\n",
    "# FILENAME AS CYCLE_RUN_ID, TIMESTAMP_CYCLE_START, CYCLE_EVAL_GROUP_NAME, STAGE_NUM, CYCLE_CHECK_MEASURE_NAME,\n",
    "# CALCULATION_TYPE_DESCR, STATUS_CHECK_DESCR, CALCULATED_VALUE, UPPER_LIMIT_AMT, LOWER_LIMIT_AMT,\n",
    "# CALCULATION_LIMIT_AMT, PRIORITY_CODE, STATUS_CHECK_RESULT, CREATED_BY, CREATED_DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "[Create spark session](#Create-spark-session)  \n",
    "[Schema sefinition](#Schema-definition)  \n",
    "[Load data](#Load-data)  \n",
    "[Helper functions](#Helper-functions)  \n",
    "[Calculation functions](#Calculation-functions)  \n",
    "[Functions map](#Functions-map)  \n",
    "[Evaluation orchestrator](#Evaluation-orchestrator)  \n",
    "[Run calculations](#Run-calculations)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import lag, col\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = SparkSession.builder.appName(\"Baxter MPA Process Calculation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RUN_TIME = \"{date:%Y-%m-%d %H:%M:%S}\".format(date=datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cycle_measures_schema = StructType([ \\\n",
    "StructField(\"FACILITY_CODE\", StringType(), True),\n",
    "StructField(\"VESSEL_CODE\", IntegerType(), True), \\\n",
    "StructField(\"CYCLE_CODE\", StringType(), True), \\\n",
    "StructField(\"CYCLE_STATUS_CODE\", StringType(), True), \\\n",
    "StructField(\"EXPOSURE_STATUS_CODE\", StringType(), True), \\\n",
    "StructField(\"TIMESTAMP\", StringType(), True), \\\n",
    "StructField(\"PC_TIME\", StringType(), True), \\\n",
    "StructField(\"CYCLE_STAGE\", StringType(), True), \\\n",
    "StructField(\"CYCLE_TIME\", FloatType(), True), \\\n",
    "StructField(\"MAX_CYCLE_STAGE\", IntegerType(), True), \\\n",
    "StructField(\"TIMESTAMP_CYCLE_START\", StringType(), True), \\\n",
    "StructField(\"FILENAME\", StringType(), True), \\\n",
    "StructField(\"VESSEL_TEMPERATURE\", FloatType(), True), \\\n",
    "StructField(\"VESSEL_TEMPERATURE_SETPT\", FloatType(), True), \\\n",
    "StructField(\"STEAM_CONTROL_VALVE\", IntegerType(), True), \\\n",
    "StructField(\"VESSEL_PRESSURE\", FloatType(), True), \\\n",
    "StructField(\"VESSEL_PRESSURE_SETPT\", IntegerType(), True), \\\n",
    "StructField(\"AIR_CONTROL_VALVE\", IntegerType(), True), \\\n",
    "StructField(\"WATER_TEMPERATURE\", FloatType(), True), \\\n",
    "StructField(\"WATER_TEMPERATURE_SETPT\", FloatType(), True), \\\n",
    "StructField(\"COOLING_CONTROL_VALVE\", IntegerType(), True), \\\n",
    "StructField(\"LEFT_AUX_TEMPERATURE\", FloatType(), True), \\\n",
    "StructField(\"RIGHT_AUX_TEMPERATURE\", FloatType(), True), \\\n",
    "StructField(\"VESSEL_REF_TEMPERATURE\", FloatType(), True), \\\n",
    "StructField(\"VESSEL_REF_PRESSURE\", FloatType(), True), \\\n",
    "StructField(\"WATER_REF_TEMPERATURE\", FloatType(), True)\n",
    "])\n",
    "\n",
    "cycle_eval_schema = StructType([ \\\n",
    "StructField(\"facility_code\", StringType(), True), \\\n",
    "StructField(\"cycle_code\", StringType(), True), \\\n",
    "StructField(\"stage_number\", StringType(), True), \\\n",
    "StructField(\"calculation_limit\", StringType(), True), \\\n",
    "StructField(\"check_evaluation_group\", StringType(), True), \\\n",
    "StructField(\"cycle_check_measure_name\", StringType(), True), \\\n",
    "StructField(\"measure_1_name\", StringType(), True), \\\n",
    "StructField(\"measure_2_name\", StringType(), True), \\\n",
    "StructField(\"calculation_type_description\", StringType(), True), \\\n",
    "StructField(\"lower_limit\", StringType(), True), \\\n",
    "StructField(\"upper_limit\", StringType(), True) \\\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cycle_measures = sqlContext.read.parquet('bax-data/cycle-measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set column names to uppercase\n",
    "new_col_names = [c.upper() for c in cycle_measures.columns]\n",
    "cycle_measures = cycle_measures.toDF(*new_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for reading from \n",
    "# cycle_measures = session.read.format('com.databricks.spark.csv') \\\n",
    "#             .options(delimiter='\\t', header='true', inferschema='false', ignoreLeadingWhiteSpace ='true', ignoreTrailingWhiteSpace ='true', treatEmptyValuesAsNulls = 'true') \\\n",
    "#             .load('/home/jovyan/work/bax-data/cycle_measures.txt', schema= cycle_measures_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FACILITY_CODE: string (nullable = true)\n",
      " |-- VESSEL_CODE: string (nullable = true)\n",
      " |-- CYCLE_CODE: string (nullable = true)\n",
      " |-- CYCLE_STATUS_CODE: string (nullable = true)\n",
      " |-- EXPOSURE_STATUS_CODE: string (nullable = true)\n",
      " |-- MEASURE_TIMESTAMP: timestamp (nullable = true)\n",
      " |-- PC_TIME: string (nullable = true)\n",
      " |-- CYCLE_STAGE: string (nullable = true)\n",
      " |-- CYCLE_TIME: double (nullable = true)\n",
      " |-- MAX_CYCLE_STAGE: string (nullable = true)\n",
      " |-- CYCLE_RUN_START_TIMESTAMP: timestamp (nullable = true)\n",
      " |-- FILENAME: string (nullable = true)\n",
      " |-- VESSEL_TEMPERATURE: double (nullable = true)\n",
      " |-- VESSEL_TEMPERATURE_SETPT: double (nullable = true)\n",
      " |-- STEAM_CONTROL_VALVE: double (nullable = true)\n",
      " |-- VESSEL_PRESSURE: double (nullable = true)\n",
      " |-- VESSEL_PRESSURE_SETPT: double (nullable = true)\n",
      " |-- AIR_CONTROL_VALVE: double (nullable = true)\n",
      " |-- WATER_TEMPERATURE: double (nullable = true)\n",
      " |-- WATER_TEMPERATURE_SETPT: double (nullable = true)\n",
      " |-- COOLING_CONTROL_VALVE: double (nullable = true)\n",
      " |-- LEFT_AUX_TEMPERATURE: double (nullable = true)\n",
      " |-- RIGHT_AUX_TEMPERATURE: double (nullable = true)\n",
      " |-- VESSEL_REF_TEMPERATURE: double (nullable = true)\n",
      " |-- VESSEL_REF_PRESSURE: double (nullable = true)\n",
      " |-- WATER_REF_TEMPERATURE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cycle_measures.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cycle_eval = session.read.format('com.databricks.spark.csv') \\\n",
    "            .options(delimiter='\\t', header='true', inferschema='false', \n",
    "                     ignoreLeadingWhiteSpace ='true', ignoreTrailingWhiteSpace ='true', treatEmptyValuesAsNulls = 'true') \\\n",
    "            .load('bax-data/cycle_eval_group_updated.txt', schema= cycle_eval_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- facility_code: string (nullable = true)\n",
      " |-- cycle_code: string (nullable = true)\n",
      " |-- stage_number: string (nullable = true)\n",
      " |-- calculation_limit: string (nullable = true)\n",
      " |-- check_evaluation_group: string (nullable = true)\n",
      " |-- cycle_check_measure_name: string (nullable = true)\n",
      " |-- measure_1_name: string (nullable = true)\n",
      " |-- measure_2_name: string (nullable = true)\n",
      " |-- calculation_type_description: string (nullable = true)\n",
      " |-- lower_limit: string (nullable = true)\n",
      " |-- upper_limit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cycle_eval.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def filter_cycle_measures(df, stages, vessel):\n",
    "#     \"\"\"Filters the cycle measures data based on the specified stages appearing in MAX_CYCLE_STAGE\"\"\"\n",
    "#     stages = stages.split(',')\n",
    "#     return df.filter((col(\"MAX_CYCLE_STAGE\").isin(stages)) & (col(\"VESSEL_CODE\") == vessel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subtract_columns(df, column_pair):\n",
    "    \"\"\"Subtracts c specified in column_pair[1] from column_pair[0] within df.  \n",
    "    Result is assigned to a new column_difference variable \"\"\"\n",
    "    df = df.withColumn(\"column_difference\", col(column_pair[0]) - col(column_pair[1]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_calc(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    \"\"\"calculates an average of the specified column\"\"\"\n",
    "    return (df.agg(F.avg(col(target_measure))).collect())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_calc(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    \"\"\"calculates a minimum of the specified column\"\"\"\n",
    "    return (df.agg(F.min(col(target_measure))).collect())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_calc(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    \"\"\"calculates a minimum of the specified column\"\"\"\n",
    "    return (df.agg(F.max(col(target_measure))).collect())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stddev_calc(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    \"\"\"calculats the standard deviation of the specified column\"\"\"\n",
    "    return (df.agg(F.stddev(col(target_measure))).collect())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def range_calc(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    max_value = (df.agg(F.max(col(target_measure))).collect())[0][0]\n",
    "    min_value = (df.agg(F.min(col(target_measure))).collect())[0][0]\n",
    "    return max_value - min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_window_calc(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    \"\"\"Finds the range in minutes between the first and last value of a datetime column\"\"\"\n",
    "    df = df.withColumn(target_measure, df[target_measure].cast(\"timestamp\"))\n",
    "    last_timestamp = (df.agg(F.max(col(target_measure))).collect())[0][0]\n",
    "    first_timestamp = (df.agg(F.min(col(target_measure))).collect())[0][0]\n",
    "    result = (last_timestamp - first_timestamp).seconds // 60\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def osc_counter(over_upper, below_lower):\n",
    "    \"\"\"Handles the oscillation counting\"\"\"\n",
    "    check_upper = True\n",
    "    check_lower = False\n",
    "    osc_count = 0\n",
    "    for i in range(len(over_upper)):\n",
    "        if check_upper:\n",
    "            if over_upper[i]:\n",
    "                osc_count += 1\n",
    "                check_upper = False\n",
    "                check_lower = True\n",
    "        if check_lower:\n",
    "            if below_lower[i]:\n",
    "                osc_count += 1\n",
    "                check_upper = True\n",
    "                check_lower = False\n",
    "    return osc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_oscillations(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    \"\"\"Calculates the oscillation count on the specified column, based on [column_avg + upper_limit, column_avg + lower_limit]\"\"\"\n",
    "    \n",
    "    column_avg = (df.agg(F.avg(col(target_measure))).collect())[0][0]\n",
    "    df = df.withColumn(\"upper_thresh\", F.lit(column_avg + upper_limit))\n",
    "    df = df.withColumn(\"lower_thresh\", F.lit(column_avg + lower_limit))\n",
    "    \n",
    "    df = df.withColumn(\"over_upper\", df[target_measure] > df[\"upper_thresh\"])\n",
    "    df = df.withColumn(\"below_lower\", df[target_measure] < df[\"lower_thresh\"])\n",
    "    over_upper = [v[0] for v in df.select(\"over_upper\").collect()]\n",
    "    below_lower = [v[0] for v in df.select(\"below_lower\").collect()]\n",
    "    \n",
    "    result = osc_counter(over_upper, below_lower)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_start_value(column):\n",
    "    \"\"\"Finds the first value in the column array\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_stop_value(column):\n",
    "    \"\"\"Finds the last value in the column array\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_above_upper_limit(column):\n",
    "    \"\"\"Calculates the amount of cycle time (in minutes) that the Values[ ] array is \n",
    "    greater than the specified Upper Limit.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_below_lower_limit(df, target_measure, upper_limit=None, lower_limit=None):\n",
    "    \"\"\"Calculates the amount of cycle time (in minutes) that the Values[ ] array is \n",
    "    below the specified Lower Limit.\"\"\"\n",
    "    # Make MEASURE_TIMESTAMP a timestamp type:\n",
    "    df = df.withColumn(\"MEASURE_TIMESTAMP\", df[\"MEASURE_TIMESTAMP\"].cast(\"timestamp\"))\n",
    "    # flag where we have the target measure below the set threshold:\n",
    "    df = df.withColumn('time_below', (df[target_measure] < lower_limit).cast('integer'))\n",
    "    \n",
    "    # use lag analytic function to get the next timestamp for all records:\n",
    "    lagwindow = Window.orderBy('MEASURE_TIMESTAMP')\n",
    "    df = df.withColumn('lagged_time', (lag('MEASURE_TIMESTAMP', -1).over(lagwindow)).cast(\"timestamp\"))\n",
    "    \n",
    "    # filter to just look at records where the time_below flag has been set, and calculate the diff\n",
    "    df = df.filter(col('time_below') == 1)\n",
    "    time_incr = F.unix_timestamp('lagged_time') - F.unix_timestamp('MEASURE_TIMESTAMP') \n",
    "    df = df.withColumn('time_below_incr', time_incr)\n",
    "    \n",
    "    result = df.agg(F.sum(col('time_below_incr'))).collect()[0][0] // 60\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionary mapping calculation descriptions to functions. Uses built-in functions where possible and defines custom functions where not.\n",
    "calculation_map = {\n",
    "    'Average': avg_calc,\n",
    "    'Minimum': min_calc,\n",
    "    'Maximum': max_calc,\n",
    "    'Standard Deviation': stddev_calc,\n",
    "    'Start Value': find_start_value,\n",
    "    'Stop Value': find_stop_value,\n",
    "    'Time Window Calc': time_window_calc,\n",
    "    'Max - Min': range_calc,\n",
    "    'Oscillation Counter': count_oscillations,\n",
    "    'Time Above Upper Limit': time_above_upper_limit,\n",
    "    'Time Below Lower Limit': time_below_lower_limit\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.40244376451706"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test passing functions from the dict:\n",
    "res = calculation_map['Average'](cycle_measures, \"CYCLE_TIME\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_evaluation(df, calc_type, calculation_map, measure_a, measure_b, upper_limit, lower_limit):\n",
    "    \"\"\"Orchestrates calculation given the calc_type, calculation_map, and selected measures a and b\"\"\"\n",
    "    if not measure_b: # only have one metric to calculate\n",
    "        calculated_value = calculation_map[calc_type](df, measure_a, upper_limit, lower_limit)\n",
    "\n",
    "    else:\n",
    "        df = subtract_columns(df, [measure_a, measure_b])\n",
    "        calculated_value = calculation_map[calc_type](df, 'column_difference', upper_limit, lower_limit)\n",
    "    \n",
    "    return calculated_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group eval_data by the relevant fields listed below\n",
    "# append other fields from cycle_eval group\n",
    "# add fields calculated from process\n",
    "# add admin fields like created_by . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   4 AS CYCLE_CHECK_ROWID,\n",
    "#   FACILITY_CODE, # from cycle_eval_group\n",
    "#   VESSEL_CODE, # from cycle_measures\n",
    "#   CYCLE_CODE, # from cycle_eval_group\n",
    "#   CYCLE_STATUS_CODE, # from cycle_measures\n",
    "#   EXPOSURE_STATUS_CODE, # from cycle_measures\n",
    "#   FILENAME AS CYCLE_RUN_ID, # from cycle_measures\n",
    "#   TIMESTAMP_CYCLE_START, # from cycle_measures\n",
    "#   'PBWS 250F ABS LIMIT CHECK' AS CYCLE_EVAL_GROUP_NAME, # from cycle_eval_group\n",
    "#   MAX_CYCLE_STAGE AS STAGE_NUM, # from cycle_eval_group\n",
    "#   'Cycle Time' AS CYCLE_CHECK_MEASURE_NAME, # from cycle_eval_group\n",
    "#   'Time Window' AS CALCULATION_TYPE_DESCR, # from cycle_eval_group\n",
    "#   'Absolute Limits Check' AS STATUS_CHECK_DESCR, # from cycle_eval_group\n",
    "#   MAX(CYCLE_TIME) - MIN(CYCLE_TIME) AS CALCULATED_VALUE, # set by process\n",
    "#   50 AS UPPER_LIMIT_AMT, # from cycle_eval_group\n",
    "#   10 AS LOWER_LIMIT_AMT, # from cycle_eval_group\n",
    "#   NULL AS CALCULATION_LIMIT_AMT, # from cycle_eval_group\n",
    "#   'N/A' AS PRIORITY_CODE, # from cycle_eval_group\n",
    "#    STATUS_CHECK_RESULT, # set by process\n",
    "#   CREATED_BY, # system\n",
    "#   CREATED_DATE # current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cycle_measures_metadata(eval_data, output_fields):\n",
    "    \"\"\"group fields needed for output from cycle_measures data\"\"\"\n",
    "    eval_data = eval_data.groupby(*output_fields).count()\n",
    "    result = eval_data[output_fields].collect()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VESSEL_CODE='2', CYCLE_STATUS_CODE='ACCEPT', EXPOSURE_STATUS_CODE='EC', FILENAME='V2M40D180728T091050_ACCEPT_EC_NC', CYCLE_RUN_START_TIMESTAMP=datetime.datetime(2018, 7, 28, 9, 10, 50)),\n",
       " Row(VESSEL_CODE='2', CYCLE_STATUS_CODE='ACCEPT', EXPOSURE_STATUS_CODE='EC', FILENAME='V2M483D180720T221705_ACCEPT_EC_NC', CYCLE_RUN_START_TIMESTAMP=datetime.datetime(2018, 7, 20, 22, 17, 5)),\n",
       " Row(VESSEL_CODE='2', CYCLE_STATUS_CODE='ACCEPT', EXPOSURE_STATUS_CODE='EC', FILENAME='V2M40D180727T121946_ACCEPT_EC_NC', CYCLE_RUN_START_TIMESTAMP=datetime.datetime(2018, 7, 27, 12, 19, 46)),\n",
       " Row(VESSEL_CODE='2', CYCLE_STATUS_CODE='ACCEPT', EXPOSURE_STATUS_CODE='EC', FILENAME='V2M395D180713T205603_ACCEPT_EC_NC', CYCLE_RUN_START_TIMESTAMP=datetime.datetime(2018, 7, 13, 20, 56, 3)),\n",
       " Row(VESSEL_CODE='2', CYCLE_STATUS_CODE='ACCEPT', EXPOSURE_STATUS_CODE='EC', FILENAME='V2M40D180725T200828_ACCEPT_EC_NC', CYCLE_RUN_START_TIMESTAMP=datetime.datetime(2018, 7, 25, 20, 8, 28))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycle_measures_outputs = ['VESSEL_CODE', 'CYCLE_STATUS_CODE', 'EXPOSURE_STATUS_CODE', 'FILENAME', \n",
    "                          'CYCLE_RUN_START_TIMESTAMP']\n",
    "\n",
    "outputs = get_cycle_measures_metadata(eval_data=cycle_measures, output_fields=cycle_measures_outputs)\n",
    "outputs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(facility_code='NC', cycle_code='126', stage_number='3,4', calculation_limit='', check_evaluation_group='PBWS 250F Abs Limit Check', cycle_check_measure_name='Cycle Time', measure_1_name='', measure_2_name='', calculation_type_description='Time Window Calc', lower_limit='10', upper_limit='50'),\n",
       " Row(facility_code='NC', cycle_code='126', stage_number='4', calculation_limit='', check_evaluation_group='PBWS 250F Abs Limit Check', cycle_check_measure_name='Cycle Time', measure_1_name='', measure_2_name='', calculation_type_description='Time Window Calc', lower_limit='10', upper_limit='50'),\n",
       " Row(facility_code='NC', cycle_code='126', stage_number='4', calculation_limit='', check_evaluation_group='PBWS 250F Abs Limit Check', cycle_check_measure_name='Left Aux - Temp Setpt', measure_1_name='Left Aux Temperature', measure_2_name='Vessel Temperature Setpt', calculation_type_description='Average', lower_limit='-10', upper_limit='10'),\n",
       " Row(facility_code='NC', cycle_code='126', stage_number='4', calculation_limit='', check_evaluation_group='PBWS 250F Abs Limit Check', cycle_check_measure_name='Right Aux - Temp Setpt', measure_1_name='Right Aux Temperature', measure_2_name='Vessel Temperature Setpt', calculation_type_description='Average', lower_limit='-10', upper_limit='10'),\n",
       " Row(facility_code='NC', cycle_code='126', stage_number='4', calculation_limit='', check_evaluation_group='PBWS 250F Abs Limit Check', cycle_check_measure_name='Ves Temp - Temp Setpt', measure_1_name='Vessel Temperature', measure_2_name='Vessel Temperature Setpt', calculation_type_description='Average', lower_limit='-10', upper_limit='10')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of evaluation calc metadata:\n",
    "#cycle_eval_filt = cycle_eval.filter(col(\"calculation_type_description\") == 'Time Below Lower Limit')\n",
    "# testing adding a comment\n",
    "evals = cycle_eval.collect()\n",
    "evals[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set of vessels to use for calculations:\n",
    "vessels_list = [v[0] for v in cycle_measures.select(\"VESSEL_CODE\").distinct().collect()]\n",
    "vessels_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_evaluation_checks(cycle_measures, evaluation_list, vessels_list, debug=False):\n",
    "    \"\"\"Runs cycle evaluation alerts across cycle measures data for each vessel in a facility according to criteria in \n",
    "    cycle evaluation_list\"\"\"\n",
    "    for v in vessels_list:\n",
    "        print('Running calculation for vessel {}'.format(v))\n",
    "        eval_data = cycle_measures\n",
    "        eval_data = eval_data.filter(col(\"VESSEL_CODE\") == v)\n",
    "    \n",
    "        for e in evaluation_list:\n",
    "            # definitions of the checks to run based on the records in cycle_eval_group:\n",
    "            facility_code, cycle_code, stage_number, calculation_limit, check_evaluation_group, cycle_check_measure_name, \\\n",
    "              measure_1_name, measure_2_name, calculation_type_description, lower_limit, upper_limit = \\\n",
    "                e['facility_code'], e['cycle_code'], e['stage_number'], e['calculation_limit'], e['check_evaluation_group'], \\\n",
    "                e['cycle_check_measure_name'], e['measure_1_name'], e['measure_2_name'], e['calculation_type_description'], \\\n",
    "                e['lower_limit'], e['upper_limit']\n",
    "            \n",
    "            # sometimes we don't get a definition of measure_1_name (could COALESCE in the SQL to build this input)\n",
    "            if measure_1_name is None or measure_1_name == '':\n",
    "                measure_1_name = cycle_check_measure_name\n",
    "            \n",
    "            if upper_limit is None:\n",
    "                upper_limit = -1\n",
    "            \n",
    "            # Remove these when we get the input format right:\n",
    "            upper_limit = float(upper_limit) \n",
    "            lower_limit = float(lower_limit)\n",
    "            \n",
    "            # other fields we need for the output:\n",
    "            max_stage_num = stage_number.split(',')[-1] # stage_number arrives as a list and we want the last value to filter cycle_measures\n",
    "    \n",
    "            # TODO: Convert values in metrics data to match casing on column names in cycle_measures data:\n",
    "            measure_1_name = measure_1_name.upper().replace(' ', '_')\n",
    "            measure_2_name = measure_2_name.upper().replace(' ', '_')\n",
    "            \n",
    "            # filter eval_data based on definitions in cycle_eval_group:\n",
    "            if not debug:\n",
    "                eval_data = eval_data.filter((col(\"MAX_CYCLE_STAGE\").isin(max_stage_num)) & \\\n",
    "                                         (col(\"CYCLE_CODE\") == cycle_code))\n",
    "    \n",
    "            if eval_data.count() > 0: # only run calcs if we have data:\n",
    "                print('Calculation used: {}'.format(calculation_type_description))\n",
    "                print('Measures used: 1) {} and 2) {}'.format(measure_1_name, measure_2_name))\n",
    "                \n",
    "                calculated_value = run_evaluation(eval_data, calculation_type_description, calculation_map, \n",
    "                                                  measure_1_name, measure_2_name, upper_limit, lower_limit)\n",
    "                \n",
    "                status_check_result = True if calculated_value < upper_limit and calculated_value > lower_limit else False\n",
    "        \n",
    "            else:\n",
    "                calculated_value = -1\n",
    "                status_check_result = False\n",
    "    \n",
    "            print('Result: {}'.format(calculated_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running calculation for vessel 1\n",
      "Calculation used: Time Window Calc\n",
      "Measures used: 1) CYCLE_TIME and 2) \n",
      "Result: 1\n",
      "Calculation used: Time Window Calc\n",
      "Measures used: 1) CYCLE_TIME and 2) \n",
      "Result: 1\n",
      "Calculation used: Average\n",
      "Measures used: 1) LEFT_AUX_TEMPERATURE and 2) VESSEL_TEMPERATURE_SETPT\n",
      "Result: -35.1023059215747\n",
      "Calculation used: Average\n",
      "Measures used: 1) RIGHT_AUX_TEMPERATURE and 2) VESSEL_TEMPERATURE_SETPT\n",
      "Result: -35.561823305286474\n",
      "Calculation used: Average\n",
      "Measures used: 1) VESSEL_TEMPERATURE and 2) VESSEL_TEMPERATURE_SETPT\n",
      "Result: -38.21365296078768\n",
      "Calculation used: Average\n",
      "Measures used: 1) LEFT_AUX_TEMPERATURE and 2) \n",
      "Result: 184.5825607239235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-be916f3895fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_evaluation_checks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_measures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvessels_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-051bdcb0e7f9>\u001b[0m in \u001b[0;36mrun_evaluation_checks\u001b[0;34m(cycle_measures, evaluation_list, vessels_list, debug)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0meval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAX_CYCLE_STAGE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_stage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m                                          \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CYCLE_CODE\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcycle_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# only run calcs if we have data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calculation used: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculation_type_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Measures used: 1) {} and 2) {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasure_1_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure_2_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         return_value = get_return_value(\n\u001b[1;32m    933\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_evaluation_checks(cycle_measures, evals, vessels_list, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
